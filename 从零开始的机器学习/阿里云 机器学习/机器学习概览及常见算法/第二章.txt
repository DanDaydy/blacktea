1.介绍算法的常见分类
2.介绍有监督学习算法，重点介绍KNN、ID3
3.介绍无监督学习算法，重点介绍Apriori、K-Means
4.介绍其他常见的算法

目标
1.了解无监督学习和有监督算法
2.KNN、ID3
3.Apriori、K-Means
4.了解集成算法等其他算法

=================================

算法
是利用计算机解决特定问题的处理步骤，是有限操作的集合


----------------------

监督式学习
学习样本中有结果标记

利用一组已知类别的样本来训练模型，使其达到性能要求。
特点为输入数据（训练数据）均有一个明确的标识或结果（标签）。
即我们提供样例“教”计算机如何学习

-------------------------

无监督学习
学习样本中无结果标记

从无标记的训练数据中推断结论。
其特点为输入数据（训练数据）不存在明确的标识或结果（标签）。
常见的无监督学习为聚类，即发现隐藏的模式或者对数据进行分组。
即计算机根据我们提供的材料“自动”学习，给定数据，寻找隐藏的机构或模式。

-------------------------

半监督学习
学习样本中部分记录有结果标记

===========================================


有监督学习

分类Classification
回归Regression
	最小二乘法


-------------

分类算法

按原理分类：
统计：贝叶斯分类
规则：决策树算法
神经网络：神经网络算法
距离：KNN（K最近邻）

常用评估指标：
精确率：预测结果与实际结果的比例
召回率：预测结果中某类结果的正覆盖率
F1-Score：统计量，综合评估分类模型，取值0-1之间


------------

KNN

k-Nearest Neighbour

核心思想：
如果离某一个样本最近的k个样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。
KNN不但可以预测分类，还可以做回归分析（预测具体的值）。


第一步，确定k的取值，确定距离公式
	欧式距离
	曼哈顿距离
	余弦相似度
k的取值不宜过大，使用交叉验证确定

第二步，计算r和所有样本点的距离
第三步，圈定符合条件的k条记录
第四步，统计样本分类，确定新纪录r的分类


repeat
	计算已知类别数据集中的点与当前之间的距离
	按照距离递增次序排列
until 样本点遍历完成
返回前k个样本点
统计k个样本点中出现频率最高的类别标签



属于lazy-learning算法


=========================================

决策树



信息熵
描述混乱程度的度量
取值范围0-1，值越大，越混乱

H(U) = E[-log p_i] = -\sum_i p_i log p_i



-------------------------------
信息增益和特征选择

信息是确定性的增加
从一个状态到另一个状态信息的变化
信息增益越大，对确定性贡献越大



构建决策树

选择而当前的最佳特征
按照取值产生
满足分支终止条件
是否有待处理分支
生成结果
处理结果




----------------------

第一级特征选择

计算整体的熵0.940

计算年龄的熵0.694
计算收入的熵0.911
计算单身的熵0.788
计算信用的熵0.892

第一层分支

第二级特征选择
第二层分支

...

生成决策树

---------------------------

ID3系列算法
Iterative Dichotomiser 3 迭代数三代

核心是信息熵，根据信息增益决定树的节点


C4.5
C50


CART
Classification and Regression Tree
核心是基尼系数
分类是二叉树
支持连续值和离散值
后剪枝进行修剪
支持回归，可以预测连续值


============================================

无监督学习算法

学习样本中无结果标记

从无标记的训练数据中推断结论。
其特点为输入数据（训练数据）不存在明确的标识或结果（标签）。
常见的无监督学习为聚类，即发现隐藏的模式或者对数据进行分组。
即计算机根据我们提供的材料“自动”学习，给定数据，寻找隐藏的机构或模式。


聚类算法
Clustering
聚类：将相似的事物聚集在一起，而将不相似的事物划分到不同的类别的过程。
它是一种探索性的分析，不必事先给出一个分类的标准，聚类分析能够从样本数据出发，自动进行分类。聚类分析所使用方法的不同，常常会得到不同的结论。

常见算法：层次聚类、划分聚类、基于密度的聚类


K-Means
K均值聚类，属于划分聚类

第一步，确定聚类个数，确定聚类中心，确定距离计算公式
	观察法
	枚举法
	其他技术手段

第二步，计算每个点和聚类中心的距离，归类


第三步，计算昂前类簇中心，更新聚类中心C_k

重复二、三，直到聚类中心不再发生变化
或者循环次数达到预先设定的阈值，结束，得到最终聚类结果


-------------

选择k个点作为初始类簇中心
repeat
	将每个样本点指派到最近的类簇中心，形成k个类簇
	重新计算每个类簇的中心
until 类簇不发生变化 or 达到最大迭代次数


======================================

关联规则
Association Rule
关联规则是反映事物与事物间相互的依存关系和关联性。
如果两个或多个事物间存在一定的关联关系，则其中一个事物能够通过其他事物预测到。
最常见的场景就是购物篮分析



根据某超市的购物篮信息，分析顾客的购物习惯，制定货物摆放或者捆绑销售策略

首先确定最小支持度和最小置信度

确定1-频繁项集
确定2-频繁项集
确定3-频繁项集

确定关联规则


=====================================

其他学习算法

半监督学习
训练数据有部分被标识，部分没有被标识，
这种模型首先需要学习数据的内在结构，以便合理的组织数据来进行预测。
旨在避免数据和资源的浪费，解决监督学习模型泛化能力不强、无监督学习的模型不精确等问题


集成学习
针对同一数据集，训练多种学习器，来解决同一问题
Bagging
Boosting
Stacking



随机森林
Random Forest



--------------------
深度学习
深度学习的概念源于人工神经网络的研究。
含多隐层的多层感知器就是一种深度学习结构。
深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。
属于机器学习研究中的一个新的领域，其动机在于建立，模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本

常见深度学习算法：
	受限波尔兹曼机  RBM
	深度信念网络  DBN
	卷积网络
	栈式自编码



----------------

增强学习  Reinforcement Learning


迁移学习  Transfer Learning


===========================

总结与回顾


















